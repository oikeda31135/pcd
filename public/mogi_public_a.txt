1.
あなたのチームは、世界中のユーザーが一般的なトピックについて投票できるモバイル ウェブ アプリケーションを開発しました。各トピックにつき、それぞれ 30 分の投票期間中に非常に多くの投票が行われることが予想されます。24 時間以内に票を集計して、将来の分析とレポートのために保存するには、どうすればよいですか。
A. Memorystore に票を保存した後、Cloud Functions を使用してデータを BigQuery に挿入し、結果を Google データポータルで表示する。
B. Pub/Sub に票をパブリッシュし、Dataflow パイプラインを使用してデータを BigQuery に挿入する。結果を Google データポータルで表示する。
C. Pub/Sub に票をパブリッシュし、Cloud Functions を使用してデータを Cloud Storage に挿入する。結果を Google データポータルで表示する。
D. Firebase でモバイル ユーザーを認証し、データを直接データベースにパブリッシュする。その後、データを CSV ファイルにエクスポートしてから、レポートのためにスプレッドシートにインポートする。

フィードバック
A. 不正解です。Memorystore はインメモリ データベースであり、データ分析には適していません。
B. 正解です。Pub/Sub では、1 秒あたり数百万件のレコードを取り込むことができ、メッセージの配信も保証されています。分析には BigQuery を使用することが推奨されます。
C. 不正解です。Cloud Functions はイベント ドリブンであり、長時間実行するタスクには向いていません。また、BigQuery ではなく blob ストアに分析データを保存することは最適とはいえません。
D. 不正解です。大きな票数を考慮すると、票を Pub/Sub に書き込むほうが適しています。さらに、データのエクスポートは一度限りの操作である一方、BigQuery にデータを保存するといつでも分析することができます。

https://cloud.google.com/pubsub/docs/publisher
https://cloud.google.com/sql/docs/mysql/create-instance
https://cloud.google.com/memorystore/
https://cloud.google.com/bigquery/docs/visualize-data-studio




2.
あなたのチームが管理しているウェブ アプリケーションは、現在、ユーザー セッションの情報をオンプレミスの PostgreSQL データベースに保存しています。このデータベースをオンプレミスに残して、ウェブ アプリケーションを Google Cloud に移行することになりました。移行後に高いレイテンシが検出されたため、クイックテストを何件か実施してデータポイントを収集し、パフォーマンスを改善する費用対効果の高い解決策をテクニカル リーダーに提案する必要があります。
説明のない画像
A. データベースを Cloud SQL に移行し、セッション データを Cloud Bigtable にインポートする。
B. データベースを BigQuery に移行し、セッション データをネイティブ モードの Firestore にインポートする。
C. データベースを Cloud SQL に移行し、セッション データをネイティブ モードの Firestore にインポートする
D. Google Cloud で Compute Engine 仮想マシンを作成して、PostgreSQL と MongoDB のサーバー ソフトウェアをインストールする。データベースをその PostgreSQL に、セッション データをその MongoDB にそれぞれ移行する。

フィードバック
A は不正解です。Bigtable はこのテストにはやや過剰です。NoSQL データベースである Bigtable は、よりパフォーマンスに優れ、時系列データ（金融市場データなど）で役立つ独自の方法でデータを保存します。
B は不正解です。BigQuery は、データ ウェアハウスです。挿入された行を更新 / 削除する機能が限定的であるため、セッションの進行状況に応じて変化するユーザー セッション データには不適切です。
C が正解です。Cloud SQL はマネージド PostgreSQL データベースで、移行時にスキーマの変更は不要です。ネイティブモードの Firestore は、ユーザー セッション情報の保存用途に推奨されており、こうしたテストに最適です。
D は不正解です。マネージド サービスが使用されておらず、データベース サーバーの管理が必要になるため、テストにかかる時間が増加します。
https://cloud.google.com/bigtable/docs/overview
https://cloud.google.com/architecture/building-scalable-web-apps-with-cloud-datastore
https://cloud.google.com/bigquery/docs/loading-data-cloud-firestore
https://cloud.google.com/sql/docs/postgres/import-export/importing
https://cloud.google.com/architecture/migrating-postgresql-to-gcp




3.
あなたの開発チームは、GitHub を使用してコードを管理しています。最近 QA チームから報告されたエラーを解決するためにデバッグをするにはどうすればよいですか。
A. コードレビュー担当者に、GitHub プルリクエストのコードの分析を依頼する。
B. Cloud デバッガを準備し、スナップショットを作成してログポイントを設定する。
C. GitHub からコードを pull して、Cloud Trace でトラブルシューティングを実行する。
D. Cloud Profiler を準備し、GitHub からコードを pull してスナップショットを作成する。

フィードバック
A は不正解です。これは手動プロセスであり、デバッグを行うものではありません。
B が正解です。Cloud デバッガによって次のことが可能です。
- デバッグのスナップショットを取得する（コード内の特定の場所で、アプリのローカル変数とコールスタックの状態を確認できます）
- コードにログポイントを追加する（再起動したり通常の機能を妨げたりせずに、実行中のサービスにロギングを挿入できます）
C は不正解です。Cloud Trace はネイティブのデバッグ機能を備えておらず、パフォーマンスの問題を追跡する目的で使用されます。
D は不正解です。Cloud Profiler ではデバッグではなく、実行中のサービスの解析を行います。
https://cloud.google.com/source-repositories/docs/debug-overview
https://cloud.google.com/source-repositories/docs/debug-snapshots
https://cloud.google.com/debugger/docs/source-options#github



4.
あなたは、Node.js で Cloud Functions の関数を記述して、ソースコードを Git リポジトリに格納しました。ソースに commit された変更が自動的にテストされるようにしたいと考えています。そこで、ソースを一意の名前の Cloud Functions の関数をデプロイし、関数をテストで呼び出した後に、削除してクリーンアップする Cloud Build 構成を記述しました。ところが、テストに失敗すると関数が削除されないことがわかりました。どうすればよいですか。
A. テストの実行前に Cloud Functions の関数を削除するようにステップの順序を変更して、結果が失敗だった場合にそのことが示されるようにする。
B. Cloud Functions 関数の削除の構成に waitFor オプションを追加して、このステップの前にテストステップを実行する必要があることを指定する。
C. テストの結果がファイルに書き込まれ、0 が返されるようにする。そのファイルに予想どおりの結果が含まれるかどうかを確認する最後のステップを、Cloud Functions 関数の削除の後に追加する。
D. テストの結果が result という環境変数に設定され、0 が返されるようにする。result に予想どおりの結果が含まれるかどうかを確認する最後のステップを、Cloud Functions 関数の削除の後に追加する。

フィードバック
A は不正解です。これは一見正しいようですが、ポイントがずれています。テストを実行する前に関数を削除しておけば最終的に関数が残らないため、よい案であるように思えるかもしれませんが、テストの実行前に関数を削除してしまうとテスト対象の関数がなくなってしまいます。プロセスを完了できても、実質的には機能していないことになります。
B は不正解です。Cloud Build の waitFor は並列するステップを同期するために使用します。あるステップで waitFor 内の直前のステップが特定され、直前のステップが失敗した場合、Cloud Build 全体が失敗となり、以後の実行が処理されなくなります。
C が正解です。Cloud Build 内にはステップ間で共有される永続ファイル システムがあります。次のような流れにプロセスを変更します。
1. Cloud Functions の関数をデプロイする。
2. Cloud Functions の関数の呼び出し結果をファイルに保存する。
3. Cloud Functions の関数を削除する。
4. ファイルの内容をテストする。
ステップ 2 が失敗なく行われるようになるので、ステップ 3 が実行され、ステップ 4 でビルド全体の結果が判明します。
D は不正解です。環境変数は、ステップが実行されるコンテナ内にローカルに存在します。ステップが完了すると、コンテナは破棄されて環境変数も一緒になくなります。したがって、環境変数は以後のステップでは使用できず、個別のステップ間の連携に利用することはできません。
https://cloud.google.com/build/docs/configuring-builds/configure-build-step-order
https://cloud.google.com/build/docs/configuring-builds/create-basic-configuration
https://cloud.google.com/build/docs/build-config




5.
あなたは、Google Kubernetes Engine（GKE）クラスタにウェブ アプリケーションをデプロイしました。Cloud Monitoring の指標を調べたところ、クラスタの CPU 負荷が 1 日を通じて変動し続けていることがわかりました。コストを最小限に抑えつつパフォーマンスを最大にするために、レプリカ数を自動調整するにはどうすればよいですか。
A. マネージド インスタンス グループ（MIG）を変更して自動スケーリングを有効にし、CPU 負荷に基づいてノードの最大数と最小数を構成する。
B. GKE クラスタでクラスタ オートスケーラーを有効にし、CPU 負荷に基づいてワークロードを自動スケーリングするよう Horizontal Pod Autoscaler（HPA）を構成する。
C. GKE クラスタでクラスタ オートスケーラーを有効にし、カスタム指標に基づいてワークロードを自動スケーリングするよう HPA を構成する。
D. MIG を変更して自動スケーリングを有効にし、CPU 負荷に基づいてノードの最大数と最小数を構成する。また、CPU 負荷に基づいてワークロードをスケールするよう Vertical Pod Autoscaler（VPA）を構成する。

フィードバック
A は不正解です。GKE で作成したインスタンス グループで Compute Engine の自動スケーリング機能を使用するべきではありません。
B が正解です。Kubernetes Deployment を自動スケーリングするには、この方法がおすすめです。
C は不正解です。CPU 指標はデフォルトで有効になっており、カスタム指標は不要です。
D は不正解です。GKE で作成したインスタンス グループで Compute Engine の自動スケーリング機能を使用するべきではありません。
https://cloud.google.com/kubernetes-engine/docs/concepts/cluster-autoscaler
https://cloud.google.com/kubernetes-engine/docs/how-to/cluster-autoscaler
https://cloud.google.com/kubernetes-engine/docs/how-to/scaling-apps




6.
あなたは、App Engine フレキシブル環境で Java アプリケーションを実行しています。アプリケーションのエラー メッセージが Error Reporting コンソールに表示されません。どうすればよいですか。
A. その Java アプリケーションに Cloud Monitoring クライアント ライブラリがバンドルされていることを確認する。
B. アプリケーション ログが正しい Regional Storage バケットに書き込まれているかを確認する。
C. ローカルでコンテナのテストを行い、アプリケーション エラーが stderr に書き込まれることを確認する。
D. API Explorer を使用して Cloud Logging ログレコードを作成し、Error Reporting によってこれが認識されることを確認する。

フィードバック
A は不正解です。App Engine 環境でのエラーレポートに外部ライブラリは必要ありません。
B は不正解です。Error Reporting は Cloud Logging 上に構築されたグローバル サービスであり、リージョン ログバケットに格納されているログや、他のプロジェクトにルーティングされたログの分析は行いません。
C が正解です。App Engine フレキシブル環境でエラーが Error Reporting に認識されるには、エラーは stderr に書き込まれる必要があります。
D は不正解です。API Explorer は Logging API で使用できますが、Error Reporting API では使用できません。
https://cloud.google.com/error-reporting/docs/troubleshooting




7.
この質問については、HipLocal のケーススタディを参照してください。
HipLocal で、アプリケーションの変更を最小限に抑えて状態を保存するには、どのデータベースを使用すればよいですか。
A. Firestore
B. BigQuery
C. Cloud SQL
D. Cloud Bigtable

フィードバック
A は不正解です。このデータベースを使用する場合、新しいデータモデルを開発して、アプリケーションのデータ アクセスコードを大幅に変更する必要があります。
B は不正解です。BigQuery は分析データベースです。
C が正解です。これはアプリケーションの変更を最小限に抑えられるマネージド サービスです。
D は不正解です。Bigtable は状態を保存する Key-Value ストアとしては適していません。
https://cloud.google.com/sql/docs/




8.
この質問については、HipLocal のケーススタディを参照してください。
HipLocal では、「同時実行ユーザーの大規模な増加に対応する」というビジネス要件を満たすソリューションの実装が求められています。適切なアプローチはどれですか。
A. 負荷テスト用ツールを使用して、アプリケーションの負荷テストを行う。
B. コード カバレッジ テスト用ツールを使用して、コード カバレッジを検証する。
C. セキュリティ解析ツールを使用して、静的なセキュリティ コード解析を実行する。
D. CI / CD ツールを使用して、リリース パイプラインにカナリアテストを導入する。

フィードバック
A が正解です。負荷テストを行うことで、使用量の増加に対応できることを確認できます。
B は不正解です。カバレッジ テストは、コード単体の検証にはよい方法ですが、大規模ワークロードの処理に役立つとは限りません。
C は不正解です。静的コード解析では、新規ユーザーが 10 倍になるケースに対応できません。
D は不正解です。この方法は、新機能を導入する場合は効果的ですが、負荷テストはできません。
https://www.atlassian.com/software/clover
https://jmeter.apache.org/
https://snyk.io/blog/secure-code-review/
https://cloud.google.com/architecture/application-deployment-and-testing-strategies#canary_test_pattern
https://cloud.google.com/blog/products/application-development/release-with-confidence-how-testing-and-cicd-can-keep-bugs-out-of-production




9.
この質問については、HipLocal のケーススタディを参照してください。
HipLocal で、信頼性への影響とコストの上昇を抑えながら、ソフトウェア リリースの速度を上げるにはどうすればよいですか。2 つ選択してください。
A. QA のためのコードフリーズを廃止し、デプロイ後に本番環境でテストする。
B. QA のためのコードフリーズを廃止し、代わりにカナリアを使用してリリースを評価する。
C. ソフトウェア リリースのテストを行う DevOps エンジニアを増員する。
D. QA のためのコードフリーズ期間を短縮するために QA テスターを増員する。
E. CI / CD プロセスを使用して、仮想マシン（VM）イメージのリリースを自動化する。

フィードバック
A. 不正解です。この方法では本番環境のバグが増加し、サービスの信頼性に影響が及びます。
B. 正解です。この方法なら上記のとおり信頼性やコストに影響を与えずに、要件を満たせます。
C. 不正解です。この方法ではコストが高くなります。
D. 不正解です。この方法ではコストが高くなります。
E. 正解です。この方法なら直接的に要件を満たせます。
https://cloud.google.com/solutions/continuous-delivery/




10.
この質問については、HipLocal のケーススタディを参照してください。HipLocal では、ユーザーの状態データを Cloud SQL に移行しています。Cloud SQL はアプリケーションと同じリージョンにデプロイされます。Google が推奨するベスト プラクティスに従いつつ要件を満たすためには、次のどの接続戦略を採用すればよいですか。
A. アプリケーションをプライベート IP アドレスに接続する。
B. Cloud SQL Proxy をデプロイして構成し、アプリケーションをプロキシに接続する。
C. MySQL クライアントをアプリケーションとともに実行し、MySQL クライアントを呼び出してデータベースに接続するようにアプリケーションを構成する。
D. Cloud SQL でパブリック IP アドレスを構成し、SSL 接続を必須にして、アプリケーションをそのパブリック IP アドレスに接続する。

間違った：Aではなく、B（サイドカーだ）

フィードバック
A は不正解です。プライベート IP アドレスへの接続には追加の手順が必要になります。
B が正解です。このプロキシによって Cloud SQL への安全な通信が確保されます。
C は不正解です。この場合、MySQL クライアントを呼び出すようにアプリケーションを開発する必要があります。
D は不正解です。接続は安全ですが、Cloud SQL が既存のアプリケーションの近くにあるのにもかかわらず Cloud SQL インスタンスへの公開アクセスが必要になります。
https://cloud.google.com/sql/docs/mysql/external-connection-methods




11.
この問題については、HipLocal のケーススタディを参照してください。
HipLocal では、ログ分析にどのようなアーキテクチャを使用すればよいですか。
A. Cloud Spanner を使用して各イベントを保存する。
B. 主な指標を Memorystore に保存するようにする。
C. Cloud Logging と BigQuery のシンクを使用する。
D. Cloud Logging と Cloud Storage のシンクを使用する。

フィードバック
A は不正解です。Cloud Spanner は分析データベースではありません。
B は不正解です。これはログ分析ソリューションではありません。
C は正解です。分析情報を提供するために、Google Cloud のスケーラブルなロギング ソリューションと BigQuery への自動シンクを利用します。
D は不正解です。簡単な分析を行うことができません（後処理が必要）。

https://cloud.google.com/logging/docs/export/configure_export_v2




12.
あなたはアプリケーションのパフォーマンスを分析しています。クラスタ内にある Cloud Bigtable の特定のテーブルが他のテーブルより使用率が高く、エンドユーザーに対してアプリケーションのパフォーマンスの一貫性がないことが確認されました。一部のテーブルでは似た名前の行キーのデータが多くなっており、それらのテーブルは使用率が高く、他のテーブルは使用率が低いことがわかりました。また、ユーザーの郵便番号が行キーの最初の要素になっており、その郵便番号から作成されたプロファイルによるアプリケーション使用率が高いこともわかりました。行キーの生成方法を可読形式に変更して、Cloud Bigtable の要求がクラスタ内で均等に分散されるようにするには、どうすればよいですか。
A. シーケンシャルに生成される整数値を使用する。
B. 可読形式の複数の属性を連結して使用する。
C. 行の内容の MD5 ハッシュのサブセットを使用する。
D. ミリ秒単位で表された UNIX エポック形式のタイムスタンプを使用する。

フィードバック
A は不正解です。元の値の分散状況によっては、シーケンシャルに生成される整数値によってホットスポット化をもたらす可能性があります。
B は正解です。十分な数の属性を区切って使用することで、十分な分散を実現できます。
C は不正解です。現在は、この方法は推奨されていません。この方法では、問題のトラブルシューティングが困難になります。
D は不正解です。タイムスタンプは行キーの候補として適切ではありません。複数の更新が短い時間に連続して発生し、ミリ秒レベルで同じ時刻に実行されると、誤って ID の競合が発生します。
https://cloud.google.com/bigtable/docs/schema-design#types_of_row_keys
https://cloud.google.com/bigtable/docs/schema-design-time-series#ensure_that_your_row_key_avoids_hotspotting




13.
あなたの会社で提供しているマルチプレーヤー ゲームは米国で人気があります。そこで今回、提供範囲を他のリージョンにも拡大することになりました。また、ユーザー同士がポイントを交換できる新機能をリリースする予定です。この機能は全世界のユーザーが利用できるようにします。会社で現在使用している MySQL バックエンドでは、ゲームをホストしている Compute Engine インスタンスが間もなく上限に達します。そのため、対象のリージョン全体での整合性と高可用性を実現できる他のデータベースに移行することを検討しています。どのデータベースを選択すればよいですか。
A. BigQuery
B. Cloud SQL
C. Cloud Spanner
D. Cloud Bigtable

フィードバック
A は不正解です。BigQuery をトランザクション データベースとして使用することはできません。
B は不正解です。Cloud SQL では複数のリージョンでの高可用性を実現できません。
C は正解です。Cloud Spanner のみがグローバルでの整合性と可用性を実現できます。
D は不正解です。Cloud Bigtable ではグローバルでの可用性を実現できません。




14.
あなたの会社では、分析を行うユースケースを増やすことを計画しています。新しいユースケースのあるデータ分析では、SQL を使用してほぼリアルタイムでイベントを分析する必要があります。対象のデータは急速な増加が見込まれており、できる限りマネージド サービスを使用したいと考えています。どうすればよいですか。
A. まず大規模な Compute Engine インスタンス上に Kafka インスタンスを作成する。その後、ソースから Kafka パイプラインにイベントをストリーミングし、Dataflow を利用してこれらのイベントを Cloud Storage に取り込む。
B. まず Pub/Sub のトピックとサブスクリプションを作成する。その後、ソースからイベントを Pub/Sub のトピックにストリーミングし、Dataflow を利用してこれらのイベントを Cloud Storage に取り込む。
C. まず Pub/Sub のトピックとサブスクリプションを作成する。その後、ソースからイベントを Pub/Sub のトピックにストリーミングし、Dataflow を利用してこれらのイベントを BigQuery に取り込む。
D. まず Pub/Sub のトピックとサブスクリプションを作成する。その後、ソースからイベントを Pub/Sub のトピックにストリーミングし、Dataflow を利用してこれらのイベントを Datastore モードの Firestore に取り込む。

フィードバック
A は不正解です。これはフルマネージド ソリューションではありません。
B は不正解です。Cloud Storage は、個々のイベントを挿入したり、SQL で分析したりする場合には適していません。
C は正解です。この説明に含まれる 3 つのプロダクトすべてが大規模にスケーリング可能です。さらに、BigQuery にデータを書き込むことで、すぐに SQL で分析できるようになります。
D は不正解です。Datastore モードの Firestore は、個別のイベントを挿入したり、分析したりする場合には適していません。




15.
あなたの組織では、テスト、ステージング、本番の 3 つの環境で、Compute Engine 仮想マシン インスタンス上で複数のアプリケーションを開発してテストを行います。アプリケーションごとに個別の開発チームがあり、本番環境に対しては各チームに最小限のアクセス権を付与し、テスト環境とステージング環境に対しては広範なアクセス権を付与するようにします。組織が最小限の権限を付与する方法で対応できるように Resource Manager の構造を設計するにはどうすればよいですか。
A. 環境ごとにプロジェクトを 1 つ作成し、アプリケーション チームのメンバーにプロジェクト レベルで Identity and Access Management (IAM) の役割を割り当てる。
B. 環境ごとにプロジェクトを 1 つ作成し、各アプリケーション チームのメンバーを Google グループにグループ化して、その Google グループにプロジェクト レベルで IAM の役割を割り当てる。
C. 環境ごと、アプリケーションごとにプロジェクトを 1 つ作成し、アプリケーション チームのメンバーにプロジェクト レベルで IAM の役割を割り当てる。
D. 環境ごと、アプリケーションごとにプロジェクトを 1 つ作成し、各アプリケーション チームのメンバーを Google グループにグループ化して、その Google グループにプロジェクト レベルで IAM の役割を割り当てる。

フィードバック
A は不正解です。各チームには、自分のチームのアプリケーションに対する権限のみが必要です。
B は不正解です。各チームには、自分のチームのアプリケーションに対する権限のみが必要です。
C は不正解です。IAM ポリシーで個々のユーザーをメンバーに追加すると、長期的には管理が困難になる可能性があります。
D は正解です。プロジェクトによって各アプリケーション チームが適切に分離されます。グループを使用してメンバーを管理すると、長期的には管理が容易になります。
https://cloud.google.com/docs/enterprise/best-practices-for-enterprise-organizations




16.
App Engine スタンダード環境にデプロイされているアプリケーションが、大量のトラフィックを受信しています。アプリケーションに変更をデプロイすることで全ユーザーに悪影響を及ぼすことを懸念しています。費用の問題から全環境での負荷テストは避けながら、できるだけ早く新機能をデプロイしたいと考えています。適切なアプローチはどれですか。
A. 本番環境のアプリケーションに対して週次の負荷テストをスケジュールする。
B. ローカルの開発環境を使用して、Google Cloud の外部で負荷テストを行う。
C. ユーザーに新機能へのアクセスを許可する前に、新バージョンとしてデプロイしてスモークテストを行う。その後、全ユーザーが新機能にアクセスできるようにする。
D. App Engine のトラフィック分割機能を使用して一部のユーザーに新機能をテストしてもらい、徐々にトラフィック分割を調整しつつ、最終的に全ユーザーが新機能にアクセスできるようにする。

フィードバック
A は不正解です。パターン化された A/B テストの実施方法があるため、定期的に個別の負荷テストを行う必要性は小さくなります。
B は不正解です。本番環境が正確にシミュレートされません。
C は不正解です。説明にあるとおり、スモークテストでは新機能をすぐに全ユーザーに公開することになります。
D は正解です。トラフィック分割により、全ユーザーに影響を与えることなく実際のユーザーによるテストを行うことができ、負荷テストの費用を削減できます。

https://cloud.google.com/appengine





17.
Cloud SQL 内に、同じ列を持つ 2 つのテーブルがあります。これらのテーブルをすばやく 1 つのテーブルに結合し、結果セットから重複する行を削除するにはどうすればよいですか。
A. Linux シェルからテーブルに対してクエリを実行し、結果を結合して単一の CSV にする。SQL で UNION ALL 演算子を使用してテーブルを結合する。
B. SQL で JOIN 演算子を使用してテーブルを結合する。
C. ネストされた WITH 句を使用してテーブルを結合する。
D. SQL で UNION 演算子を使用してテーブルを結合する。

フィードバック
A は不正解です。UNION ALL では重複レコードが削除されません。
B は不正解です。結合される可能性がある列の指定がありません。
C は不正解です。WITH 句は単に内部テーブルとしてクエリの結果を定義するだけです。
D は正解です。UNION 演算子では、重複レコードを削除して結果セットが結合されます。
https://www.techonthenet.com/sql/union.php
https://cloud.google.com/sql




18.
あなたの組織のウェブサイトは Compute Engine にデプロイされています。マーケティング チームでは、異なる 3 つのデザインのウェブサイトでコンバージョン率をテストしたいと考えています。アプリケーションのコードを変更することはできません。どうすればよいですか。
A. ウェブサイトを App Engine にデプロイし、トラフィック分割を使用する。
B. ウェブサイトを 3 つの個別のサービスとして App Engine にデプロイする。
C. ウェブサイトを Cloud Functions にデプロイし、カスタムコードを実装して異なるデザインを表示する。
D. ウェブサイトを 3 つの個別の機能として Cloud Functions にデプロイする。

フィードバック
A は正解です。トラフィックを単一のドメインにルーティングし、IP または Cookie に基づいてトラフィックを分割します。
B は不正解です。ドメイン名はサービスに基づいて変更されます。
C と D は不正解です。Cloud Functions はウェブサイトのデプロイには使用できません。
https://cloud.google.com/appengine/docs/standard/python/splitting-traffic




19.
あなたは会社のリージョンに分析用 Hadoop クラスタ向けにストレージ レイヤを構築しようとしています。このクラスタでは、毎晩複数のジョブが実行されます。また、頻繁にデータにアクセスする必要があります。この目的で Cloud Storage を使用する場合、最も費用効果の高いオプションはどれですか。
A. Multi-Regional Standard Storage
B. Regional Standard Storage
C. Regional Nearline Storage
D. Regional Coldline Storage

フィードバック
A は不正解です。Multi-Regional Storage では、Hadoop クラスタ以外のリージョンにデータが配置される可能性があり、クラスタによるリクエストのレイテンシが増加する場合があります。
B は正解です。要件によっては最も費用効果が高くなります。
C は不正解です。Nearline Storage は、月に 1 回のみデータにアクセスする必要がある場合に使用されます。
D は不正解です。Coldline Storage は、年に 1 回のみデータにアクセスする必要がある場合に使用されます。
https://cloud.google.com/storage/docs/storage-classes#available_storage_classes
https://cloud.google.com/storage/docs/storage-classes#standard-availability




20.
ユーザーからの入力を処理するアプリケーションがあります。入力内容に基づいて、アプリケーションは異なるバックグラウンド タスクを起動する必要があります。ユーザーによる入力が送信されたらすぐにこれらのタスクが自動的に非同期で実行されるようにするには、どのプロダクトを使用すればよいですか。
A. Cloud Tasks
B. Cloud Bigtable
C. Pub/Sub
D. Cloud Composer

間違い：CではなくA
フィードバック
A は正解です。これは標準的なユースケースです。
B は不正解です。Cloud Bigtable は単なるデータベースです。
C は不正解です。Pub/Sub は単なるメッセージング システムです。
D は不正解です。Cloud Composer はユーザーからの入力を処理する場合には適していません。





21.
配列フィールドがあるテーブルを含む BigQuery にデータ ウェアハウスが構築されています。特定のユースケースにて標準 SQL を使用してデータを分析するには、すべての要素を配列から読み取り、その他の配列以外のフィールドも全て一緒にテーブルに書き込む必要があります。配列以外のフィールドのレコードが配列フィールドのレコードに対応しない場合でもレコードを失わないようにするには、どうすればよいですか。
A. SELECT * FROM [テーブル名] を実行する。
B. UNNEST と JOIN を使用して対象のテーブルと結合し、結果を取得する。
C. UNNEST と INNER JOIN を使用して対象のテーブルと結合し、結果を取得する。
D. UNNEST と CROSS JOIN を使用して対象のテーブルと結合し、結果を取得する。

フィードバック
A は不正解です。レコードが結合されません。
B は不正解です。レコードが失われる可能性があります。
C は不正解です。レコードが失われる可能性があります。
D は正解です。結合を行ってもレコードは失われません。
https://cloud.google.com/bigquery/docs/reference/standard-sql/query-syntax#join-types




22.
あなたはマネージド インスタンス グループにウェブサイトをデプロイしました。マネージド インスタンス グループのサイズは 3 で、ポート 80 で HTTP ヘルスチェックを実行するように設定されています。マネージド インスタンス グループが作成されると 3 つのインスタンスが作成、起動されます。SSH を使用してインスタンスに接続し、ウェブサイトが稼働しており、ポート 80 で利用できることを確認します。しかしながら、マネージド インスタンス グループは、検証に失敗しインスタンスを再作成します。どうすればよいですか。
A. 管理対象外のインスタンス グループに種類を変更する。
B. マネージド インスタンス グループで自動スケーリングを無効にする。
C. 初期遅延のタイムアウトの時間を長くしてインスタンスが作成されるようにする。
D. ファイアウォール ルールを確認し、インスタンスにアクセスできるか見極める。

フィードバック
A は不正解です。インスタンス グループの種類が問題であるという説明はありません。
B は不正解です。このシナリオでは、自動スケーリングが設定されていることには触れられていません。
C は不正解です。SSH を使用してインスタンスに接続すると、ウェブサイトが稼働していることを確認できます。
D は正解です。インスタンスは作成済みであり、ウェブサイトは機能していますが、ヘルスチェックの検証が失敗しています。

https://cloud.google.com/compute/docs/instance-groups/creating-groups-of-managed-instances#monitoring_groups



23.
あなたのチームでは App Engine を使用してすべての Pub/Sub メッセージを Cloud Storage オブジェクトと BigQuery テーブルの両方に書き込んでいます。運用上のオーバーヘッドを最小限に抑えるには、どのアーキテクチャを実装すればよいですか。
(図:mogi_23.jpg）
A.
B.
C.
D.

フィードバック
A は不正解です。この場合、メッセージの半分を BigQuery に書き込み、残りの半分を Cloud Storage に書き込みます。これでは要件を満たしません。
B は正解です。各 App Engine サービスは、書き込むメッセージを個別に取得します。また、再試行、失敗を個別に処理できます。
C は不正解です。1 つのシステムに対するメッセージ処理が失敗すると、BigQuery または Cloud Storage に重複して書き込む原因となる可能性があります。
D は不正解です。メッセージ送信の料金が重複します。また、異なる 2 つのトピックにメッセージをそれぞれ送信する必要があります。これではクライアント側で費用が増し、追加のトピックを管理する必要性および複雑度も増加します




24.
組織が成長し、新しいチームでは複数プロジェクトのネットワーク接続を管理するためのアクセス権が必要です。現在、アプリケーションで断続的なタイムアウト エラーが発生しています。問題の原因を確認するにはどうすればよいですか。
A. 各 Google Cloud 仮想マシン インスタンスに Wireshark を設定する。
B. アプリケーション インスタンスのインスタンス管理アクティビティのログを Cloud Logging で確認する。
C. VPC の各サブネットに VPC フローログを設定する。
D. VPC の各ファイアウォールにファイアウォール ルールのログを設定する。


間違い：BではなくC
フィードバック
A は不正解です。規模が大きくなると管理できなくなります（特に自動スケーリングを使用する場合）。
B は不正解です。ログはネットワークにはほとんど関係がありません。
C は正解です。特定の基盤となるログを使用してすべての情報を取得します。
D は不正解です。タイムアウトは断続的であり、永続的ではないため、ファイアウォール ルールが原因ではありません。




25.
アプリケーションが systemd サービスとして VM 上で起動します。このアプリケーションは、ログの情報を stdout に出力します。アプリケーション ログを確認するにはどうすればよいですか。
A. Cloud Logging の Compute Engine VM インスタンスのアクティビティ ログでアプリケーション ログを確認する。
B. Cloud Logging の Compute Engine VM インスタンスのデータアクセス ログでアプリケーション ログを確認する。
C. Cloud Logging エージェントをインストールし、Cloud Logging の Compute Engine VM インスタンスの syslog ログでアプリケーション ログを確認する。
D. Cloud Logging エージェントをインストールし、Cloud Logging の Compute Engine VM インスタンスのシステム イベント ログでアプリケーション ログを確認する。

フィードバック
A は不正解です。管理アクティビティ ログでは、VM インスタンスのイベントの破棄、作成、変更などを確認できます（https://cloud.google.com/logging/docs/audit/#admin-activity）。
B は不正解です。データアクセス ログでは、読み取りのアクティビティを確認できます（https://cloud.google.com/logging/docs/audit/#data-access）。
C は正解です。systemd で実行されるサービスが stdout に出力する場合は、syslog にログが出力され、Logging エージェントがそれを取得します(https://cloud.google.com/logging/docs/agent/installation)（https://github.com/GoogleCloudPlatform/fluentd-catch-all-config/tree/master/configs/config.d）。
D は不正解です。システム イベント ログでは、ライブ マイグレーションなどの情報を確認できます(https://cloud.google.com/logging/docs/agent/installation)(https://cloud.google.com/logging/docs/audit/#system-event) 。





26.
Cloud Logging で、重要な監査アクティビティの情報を取得しています。Cloud Logging から情報を読み取り、リアルタイムでログの分析を行う必要があります。複数のプロセスで、ログデータに対して異なる種類の分析を行うにはどうすればよいですか。
A. Cloud Logging API でログを直接読み取る。
B. Cloud Logging から BigQuery への同期を設定し、BigQuery テーブルからログを読み取る。
C. Cloud Logging から Pub/Sub への同期を設定し、Pub/Sub のトピックからログを読み取る。
D. Cloud Logging から Cloud Storage への同期を設定し、Cloud Storage のバケットからログを読み取る。


間違い：DではなくC
フィードバック
A は不正解です。API には読み取りに関する制限があり、複数の読み取り処理を行うソリューションには適していません（https://cloud.google.com/logging/quotas）。
B は不正解です。このソリューションはリアルタイムではありません（https://cloud.google.com/logging/docs/export/using_exported_logs#bigquery-availability）。
C は正解です。このソリューションはリアルタイムです（https://cloud.google.com/logging/docs/export/using_exported_logs#pubsub-availability）。
D は不正解です。このソリューションはリアルタイムではありません（https://cloud.google.com/logging/docs/export/using_exported_logs#gcs-availability）。




27.
データ移行の一部として、オンプレミスの仮想マシンから Cloud Storage にファイルをアップロードしようとしています。これらのファイルは、Google Cloud 環境の Dataproc Hadoop クラスタで使用されます。どのコマンドを使用すればよいですか。
A. gsutil cp [ローカル オブジェクト] gs://[転送先バケット名]/
B. gcloud cp [ローカル オブジェクト] gs://[転送先バケット名]/
C. hadoop fs cp [ローカル オブジェクト] gs://[転送先バケット名]/
D. gcloud dataproc cp [ローカル オブジェクト] gs://[転送先バケット名]/

フィードバック
A は正解です。Cloud Storage を操作するための適切な CLI ツールが使用されています。
B は不正解です。Cloud Storage を操作するには gsutil コマンドを使用します。
C は不正解です。Cloud Storage を操作するには gsutil コマンドを使用します。
D は不正解です。Cloud Storage を操作するには gsutil コマンドを使用します。





28.
あなたは API エンドポイントを記述しています。このエンドポイントでは、ウェブ アプリケーションからの注文を処理し、Datastore コレクションにデータを保存します。アプリケーションのテスト中に、次の事象に気がつきました。Datastore API から HTTP 5xx サーバーエラーが返されると、アプリケーションはこのエラーを検知し HTTP 200 OK のレスポンス コードをクライアントに返しますが、Datastore にはデータが保存されません。書き込みリクエストが失敗した場合に、API エンドポイントの利用者に通知するようにするにはどうすればよいですか。
A. HTTP 204 No Content のレスポンスを返す。
B. HTTP 406 Not Acceptable のレスポンスを返す。
C. HTTP 500 Internal Server Error のレスポンスを返す。
D. Datastore が HTTP 2xx のレスポンスを返すまで、指数バックオフを使用して Datastore API を再試行する。

フィードバック
A は不正解です。2xx のコードは、サーバーからの成功のレスポンスを表しています。
B は不正解です。406 は、リクエストの Accept ヘッダーに、サーバーで受理できない内容が含まれている場合に送信されます。
C は正解です。500 番台のレスポンスの場合は、API 呼び出しが失敗したことをクライアントがはっきり認識できるため、クライアントは個別に再送信できます。
D は不正解です。Datastore API が 500 番台以外のレスポンスで応答するタイミングは決まっていません。
https://www.restapitutorial.com/httpstatuscodes.html
