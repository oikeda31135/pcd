1.
あなたのチームは、世界中のユーザーが一般的なトピックについて投票できるモバイル ウェブ アプリケーションを開発しました。各トピックにつき、それぞれ 30 分の投票期間中に非常に多くの投票が行われることが予想されます。24 時間以内に票を集計して、将来の分析とレポートのために保存するには、どうすればよいですか。
A. Memorystore に票を保存した後、Cloud Functions を使用してデータを BigQuery に挿入し、結果を Google データポータルで表示する。
B. Pub/Sub に票をパブリッシュし、Dataflow パイプラインを使用してデータを BigQuery に挿入する。結果を Google データポータルで表示する。
C. Pub/Sub に票をパブリッシュし、Cloud Functions を使用してデータを Cloud Storage に挿入する。結果を Google データポータルで表示する。
D. Firebase でモバイル ユーザーを認証し、データを直接データベースにパブリッシュする。その後、データを CSV ファイルにエクスポートしてから、レポートのためにスプレッドシートにインポートする。



2.
あなたのチームが管理しているウェブ アプリケーションは、現在、ユーザー セッションの情報をオンプレミスの PostgreSQL データベースに保存しています。このデータベースをオンプレミスに残して、ウェブ アプリケーションを Google Cloud に移行することになりました。移行後に高いレイテンシが検出されたため、クイックテストを何件か実施してデータポイントを収集し、パフォーマンスを改善する費用対効果の高い解決策をテクニカル リーダーに提案する必要があります。
説明のない画像
A. データベースを Cloud SQL に移行し、セッション データを Cloud Bigtable にインポートする。
B. データベースを BigQuery に移行し、セッション データをネイティブ モードの Firestore にインポートする。
C. データベースを Cloud SQL に移行し、セッション データをネイティブ モードの Firestore にインポートする
D. Google Cloud で Compute Engine 仮想マシンを作成して、PostgreSQL と MongoDB のサーバー ソフトウェアをインストールする。データベースをその PostgreSQL に、セッション データをその MongoDB にそれぞれ移行する。



3.
あなたの開発チームは、GitHub を使用してコードを管理しています。最近 QA チームから報告されたエラーを解決するためにデバッグをするにはどうすればよいですか。
A. コードレビュー担当者に、GitHub プルリクエストのコードの分析を依頼する。
B. Cloud デバッガを準備し、スナップショットを作成してログポイントを設定する。
C. GitHub からコードを pull して、Cloud Trace でトラブルシューティングを実行する。
D. Cloud Profiler を準備し、GitHub からコードを pull してスナップショットを作成する。



4.
あなたは、Node.js で Cloud Functions の関数を記述して、ソースコードを Git リポジトリに格納しました。ソースに commit された変更が自動的にテストされるようにしたいと考えています。そこで、ソースを一意の名前の Cloud Functions の関数をデプロイし、関数をテストで呼び出した後に、削除してクリーンアップする Cloud Build 構成を記述しました。ところが、テストに失敗すると関数が削除されないことがわかりました。どうすればよいですか。
A. テストの実行前に Cloud Functions の関数を削除するようにステップの順序を変更して、結果が失敗だった場合にそのことが示されるようにする。
B. Cloud Functions 関数の削除の構成に waitFor オプションを追加して、このステップの前にテストステップを実行する必要があることを指定する。
C. テストの結果がファイルに書き込まれ、0 が返されるようにする。そのファイルに予想どおりの結果が含まれるかどうかを確認する最後のステップを、Cloud Functions 関数の削除の後に追加する。
D. テストの結果が result という環境変数に設定され、0 が返されるようにする。result に予想どおりの結果が含まれるかどうかを確認する最後のステップを、Cloud Functions 関数の削除の後に追加する。



5.
あなたは、Google Kubernetes Engine（GKE）クラスタにウェブ アプリケーションをデプロイしました。Cloud Monitoring の指標を調べたところ、クラスタの CPU 負荷が 1 日を通じて変動し続けていることがわかりました。コストを最小限に抑えつつパフォーマンスを最大にするために、レプリカ数を自動調整するにはどうすればよいですか。
A. マネージド インスタンス グループ（MIG）を変更して自動スケーリングを有効にし、CPU 負荷に基づいてノードの最大数と最小数を構成する。
B. GKE クラスタでクラスタ オートスケーラーを有効にし、CPU 負荷に基づいてワークロードを自動スケーリングするよう Horizontal Pod Autoscaler（HPA）を構成する。
C. GKE クラスタでクラスタ オートスケーラーを有効にし、カスタム指標に基づいてワークロードを自動スケーリングするよう HPA を構成する。
D. MIG を変更して自動スケーリングを有効にし、CPU 負荷に基づいてノードの最大数と最小数を構成する。また、CPU 負荷に基づいてワークロードをスケールするよう Vertical Pod Autoscaler（VPA）を構成する。



6.
あなたは、App Engine フレキシブル環境で Java アプリケーションを実行しています。アプリケーションのエラー メッセージが Error Reporting コンソールに表示されません。どうすればよいですか。
A. その Java アプリケーションに Cloud Monitoring クライアント ライブラリがバンドルされていることを確認する。
B. アプリケーション ログが正しい Regional Storage バケットに書き込まれているかを確認する。
C. ローカルでコンテナのテストを行い、アプリケーション エラーが stderr に書き込まれることを確認する。
D. API Explorer を使用して Cloud Logging ログレコードを作成し、Error Reporting によってこれが認識されることを確認する。



7.
この質問については、HipLocal のケーススタディを参照してください。
HipLocal で、アプリケーションの変更を最小限に抑えて状態を保存するには、どのデータベースを使用すればよいですか。
A. Firestore
B. BigQuery
C. Cloud SQL
D. Cloud Bigtable



8.
この質問については、HipLocal のケーススタディを参照してください。
HipLocal では、「同時実行ユーザーの大規模な増加に対応する」というビジネス要件を満たすソリューションの実装が求められています。適切なアプローチはどれですか。
A. 負荷テスト用ツールを使用して、アプリケーションの負荷テストを行う。
B. コード カバレッジ テスト用ツールを使用して、コード カバレッジを検証する。
C. セキュリティ解析ツールを使用して、静的なセキュリティ コード解析を実行する。
D. CI / CD ツールを使用して、リリース パイプラインにカナリアテストを導入する。



9.
この質問については、HipLocal のケーススタディを参照してください。
HipLocal で、信頼性への影響とコストの上昇を抑えながら、ソフトウェア リリースの速度を上げるにはどうすればよいですか。2 つ選択してください。
A. QA のためのコードフリーズを廃止し、デプロイ後に本番環境でテストする。
B. QA のためのコードフリーズを廃止し、代わりにカナリアを使用してリリースを評価する。
C. ソフトウェア リリースのテストを行う DevOps エンジニアを増員する。
D. QA のためのコードフリーズ期間を短縮するために QA テスターを増員する。
E. CI / CD プロセスを使用して、仮想マシン（VM）イメージのリリースを自動化する。



10.
この質問については、HipLocal のケーススタディを参照してください。
HipLocal では、ユーザーの状態データを Cloud SQL に移行しています。Cloud SQL はアプリケーションと同じリージョンにデプロイされます。Google が推奨するベスト プラクティスに従いつつ要件を満たすためには、次のどの接続戦略を採用すればよいですか。
A. アプリケーションをプライベート IP アドレスに接続する。
B. Cloud SQL Proxy をデプロイして構成し、アプリケーションをプロキシに接続する。
C. MySQL クライアントをアプリケーションとともに実行し、MySQL クライアントを呼び出してデータベースに接続するようにアプリケーションを構成する。
D. Cloud SQL でパブリック IP アドレスを構成し、SSL 接続を必須にして、アプリケーションをそのパブリック IP アドレスに接続する。


11.
この問題については、HipLocal のケーススタディを参照してください。
HipLocal では、ログ分析にどのようなアーキテクチャを使用すればよいですか。
A. Cloud Spanner を使用して各イベントを保存する。
B. 主な指標を Memorystore に保存するようにする。
C. Cloud Logging と BigQuery のシンクを使用する。
D. Cloud Logging と Cloud Storage のシンクを使用する。



12.
あなたはアプリケーションのパフォーマンスを分析しています。クラスタ内にある Cloud Bigtable の特定のテーブルが他のテーブルより使用率が高く、エンドユーザーに対してアプリケーションのパフォーマンスの一貫性がないことが確認されました。一部のテーブルでは似た名前の行キーのデータが多くなっており、それらのテーブルは使用率が高く、他のテーブルは使用率が低いことがわかりました。また、ユーザーの郵便番号が行キーの最初の要素になっており、その郵便番号から作成されたプロファイルによるアプリケーション使用率が高いこともわかりました。行キーの生成方法を可読形式に変更して、Cloud Bigtable の要求がクラスタ内で均等に分散されるようにするには、どうすればよいですか。
A. シーケンシャルに生成される整数値を使用する。
B. 可読形式の複数の属性を連結して使用する。
C. 行の内容の MD5 ハッシュのサブセットを使用する。
D. ミリ秒単位で表された UNIX エポック形式のタイムスタンプを使用する。



13.
あなたの会社で提供しているマルチプレーヤー ゲームは米国で人気があります。そこで今回、提供範囲を他のリージョンにも拡大することになりました。また、ユーザー同士がポイントを交換できる新機能をリリースする予定です。この機能は全世界のユーザーが利用できるようにします。会社で現在使用している MySQL バックエンドでは、ゲームをホストしている Compute Engine インスタンスが間もなく上限に達します。そのため、対象のリージョン全体での整合性と高可用性を実現できる他のデータベースに移行することを検討しています。どのデータベースを選択すればよいですか。
A. BigQuery
B. Cloud SQL
C. Cloud Spanner
D. Cloud Bigtable



14.
あなたの会社では、分析を行うユースケースを増やすことを計画しています。新しいユースケースのあるデータ分析では、SQL を使用してほぼリアルタイムでイベントを分析する必要があります。対象のデータは急速な増加が見込まれており、できる限りマネージド サービスを使用したいと考えています。どうすればよいですか。
A. まず大規模な Compute Engine インスタンス上に Kafka インスタンスを作成する。その後、ソースから Kafka パイプラインにイベントをストリーミングし、Dataflow を利用してこれらのイベントを Cloud Storage に取り込む。
B. まず Pub/Sub のトピックとサブスクリプションを作成する。その後、ソースからイベントを Pub/Sub のトピックにストリーミングし、Dataflow を利用してこれらのイベントを Cloud Storage に取り込む。
C. まず Pub/Sub のトピックとサブスクリプションを作成する。その後、ソースからイベントを Pub/Sub のトピックにストリーミングし、Dataflow を利用してこれらのイベントを BigQuery に取り込む。
D. まず Pub/Sub のトピックとサブスクリプションを作成する。その後、ソースからイベントを Pub/Sub のトピックにストリーミングし、Dataflow を利用してこれらのイベントを Datastore モードの Firestore に取り込む。



15.
あなたの組織では、テスト、ステージング、本番の 3 つの環境で、Compute Engine 仮想マシン インスタンス上で複数のアプリケーションを開発してテストを行います。アプリケーションごとに個別の開発チームがあり、本番環境に対しては各チームに最小限のアクセス権を付与し、テスト環境とステージング環境に対しては広範なアクセス権を付与するようにします。組織が最小限の権限を付与する方法で対応できるように Resource Manager の構造を設計するにはどうすればよいですか。
A. 環境ごとにプロジェクトを 1 つ作成し、アプリケーション チームのメンバーにプロジェクト レベルで Identity and Access Management (IAM) の役割を割り当てる。
B. 環境ごとにプロジェクトを 1 つ作成し、各アプリケーション チームのメンバーを Google グループにグループ化して、その Google グループにプロジェクト レベルで IAM の役割を割り当てる。
C. 環境ごと、アプリケーションごとにプロジェクトを 1 つ作成し、アプリケーション チームのメンバーにプロジェクト レベルで IAM の役割を割り当てる。
D. 環境ごと、アプリケーションごとにプロジェクトを 1 つ作成し、各アプリケーション チームのメンバーを Google グループにグループ化して、その Google グループにプロジェクト レベルで IAM の役割を割り当てる。



16.
App Engine スタンダード環境にデプロイされているアプリケーションが、大量のトラフィックを受信しています。アプリケーションに変更をデプロイすることで全ユーザーに悪影響を及ぼすことを懸念しています。費用の問題から全環境での負荷テストは避けながら、できるだけ早く新機能をデプロイしたいと考えています。適切なアプローチはどれですか。
A. 本番環境のアプリケーションに対して週次の負荷テストをスケジュールする。
B. ローカルの開発環境を使用して、Google Cloud の外部で負荷テストを行う。
C. ユーザーに新機能へのアクセスを許可する前に、新バージョンとしてデプロイしてスモークテストを行う。その後、全ユーザーが新機能にアクセスできるようにする。
D. App Engine のトラフィック分割機能を使用して一部のユーザーに新機能をテストしてもらい、徐々にトラフィック分割を調整しつつ、最終的に全ユーザーが新機能にアクセスできるようにする。



17.
Cloud SQL 内に、同じ列を持つ 2 つのテーブルがあります。これらのテーブルをすばやく 1 つのテーブルに結合し、結果セットから重複する行を削除するにはどうすればよいですか。
A. Linux シェルからテーブルに対してクエリを実行し、結果を結合して単一の CSV にする。SQL で UNION ALL 演算子を使用してテーブルを結合する。
B. SQL で JOIN 演算子を使用してテーブルを結合する。
C. ネストされた WITH 句を使用してテーブルを結合する。
D. SQL で UNION 演算子を使用してテーブルを結合する。



18.
あなたの組織のウェブサイトは Compute Engine にデプロイされています。マーケティング チームでは、異なる 3 つのデザインのウェブサイトでコンバージョン率をテストしたいと考えています。アプリケーションのコードを変更することはできません。どうすればよいですか。
A. ウェブサイトを App Engine にデプロイし、トラフィック分割を使用する。
B. ウェブサイトを 3 つの個別のサービスとして App Engine にデプロイする。
C. ウェブサイトを Cloud Functions にデプロイし、カスタムコードを実装して異なるデザインを表示する。
D. ウェブサイトを 3 つの個別の機能として Cloud Functions にデプロイする。



19.
あなたは会社のリージョンに分析用 Hadoop クラスタ向けにストレージ レイヤを構築しようとしています。このクラスタでは、毎晩複数のジョブが実行されます。また、頻繁にデータにアクセスする必要があります。この目的で Cloud Storage を使用する場合、最も費用効果の高いオプションはどれですか。
A. Multi-Regional Standard Storage
B. Regional Standard Storage
C. Regional Nearline Storage
D. Regional Coldline Storage



20.
ユーザーからの入力を処理するアプリケーションがあります。入力内容に基づいて、アプリケーションは異なるバックグラウンド タスクを起動する必要があります。ユーザーによる入力が送信されたらすぐにこれらのタスクが自動的に非同期で実行されるようにするには、どのプロダクトを使用すればよいですか。
A. Cloud Tasks
B. Cloud Bigtable
C. Pub/Sub
D. Cloud Composer



21.
配列フィールドがあるテーブルを含む BigQuery にデータ ウェアハウスが構築されています。特定のユースケースにて標準 SQL を使用してデータを分析するには、すべての要素を配列から読み取り、その他の配列以外のフィールドも全て一緒にテーブルに書き込む必要があります。配列以外のフィールドのレコードが配列フィールドのレコードに対応しない場合でもレコードを失わないようにするには、どうすればよいですか。
A. SELECT * FROM [テーブル名] を実行する。
B. UNNEST と JOIN を使用して対象のテーブルと結合し、結果を取得する。
C. UNNEST と INNER JOIN を使用して対象のテーブルと結合し、結果を取得する。
D. UNNEST と CROSS JOIN を使用して対象のテーブルと結合し、結果を取得する。



22.
あなたはマネージド インスタンス グループにウェブサイトをデプロイしました。マネージド インスタンス グループのサイズは 3 で、ポート 80 で HTTP ヘルスチェックを実行するように設定されています。マネージド インスタンス グループが作成されると 3 つのインスタンスが作成、起動されます。SSH を使用してインスタンスに接続し、ウェブサイトが稼働しており、ポート 80 で利用できることを確認します。しかしながら、マネージド インスタンス グループは、検証に失敗しインスタンスを再作成します。どうすればよいですか。
A. 管理対象外のインスタンス グループに種類を変更する。
B. マネージド インスタンス グループで自動スケーリングを無効にする。
C. 初期遅延のタイムアウトの時間を長くしてインスタンスが作成されるようにする。
D. ファイアウォール ルールを確認し、インスタンスにアクセスできるか見極める。



23.
あなたのチームでは App Engine を使用してすべての Pub/Sub メッセージを Cloud Storage オブジェクトと BigQuery テーブルの両方に書き込んでいます。運用上のオーバーヘッドを最小限に抑えるには、どのアーキテクチャを実装すればよいですか。
(図:mogi_23.jpg）
A.
B.
C.
D.



24.
組織が成長し、新しいチームでは複数プロジェクトのネットワーク接続を管理するためのアクセス権が必要です。現在、アプリケーションで断続的なタイムアウト エラーが発生しています。問題の原因を確認するにはどうすればよいですか。
A. 各 Google Cloud 仮想マシン インスタンスに Wireshark を設定する。
B. アプリケーション インスタンスのインスタンス管理アクティビティのログを Cloud Logging で確認する。
C. VPC の各サブネットに VPC フローログを設定する。
D. VPC の各ファイアウォールにファイアウォール ルールのログを設定する。



25.
アプリケーションが systemd サービスとして VM 上で起動します。このアプリケーションは、ログの情報を stdout に出力します。アプリケーション ログを確認するにはどうすればよいですか。
A. Cloud Logging の Compute Engine VM インスタンスのアクティビティ ログでアプリケーション ログを確認する。
B. Cloud Logging の Compute Engine VM インスタンスのデータアクセス ログでアプリケーション ログを確認する。
C. Cloud Logging エージェントをインストールし、Cloud Logging の Compute Engine VM インスタンスの syslog ログでアプリケーション ログを確認する。
D. Cloud Logging エージェントをインストールし、Cloud Logging の Compute Engine VM インスタンスのシステム イベント ログでアプリケーション ログを確認する。



26.
Cloud Logging で、重要な監査アクティビティの情報を取得しています。Cloud Logging から情報を読み取り、リアルタイムでログの分析を行う必要があります。複数のプロセスで、ログデータに対して異なる種類の分析を行うにはどうすればよいですか。
A. Cloud Logging API でログを直接読み取る。
B. Cloud Logging から BigQuery への同期を設定し、BigQuery テーブルからログを読み取る。
C. Cloud Logging から Pub/Sub への同期を設定し、Pub/Sub のトピックからログを読み取る。
D. Cloud Logging から Cloud Storage への同期を設定し、Cloud Storage のバケットからログを読み取る。



27.
データ移行の一部として、オンプレミスの仮想マシンから Cloud Storage にファイルをアップロードしようとしています。これらのファイルは、Google Cloud 環境の Dataproc Hadoop クラスタで使用されます。どのコマンドを使用すればよいですか。
A. gsutil cp [ローカル オブジェクト] gs://[転送先バケット名]/
B. gcloud cp [ローカル オブジェクト] gs://[転送先バケット名]/
C. hadoop fs cp [ローカル オブジェクト] gs://[転送先バケット名]/
D. gcloud dataproc cp [ローカル オブジェクト] gs://[転送先バケット名]/



28.
あなたは API エンドポイントを記述しています。このエンドポイントでは、ウェブ アプリケーションからの注文を処理し、Datastore コレクションにデータを保存します。アプリケーションのテスト中に、次の事象に気がつきました。Datastore API から HTTP 5xx サーバーエラーが返されると、アプリケーションはこのエラーを検知し HTTP 200 OK のレスポンス コードをクライアントに返しますが、Datastore にはデータが保存されません。書き込みリクエストが失敗した場合に、API エンドポイントの利用者に通知するようにするにはどうすればよいですか。
A. HTTP 204 No Content のレスポンスを返す。
B. HTTP 406 Not Acceptable のレスポンスを返す。
C. HTTP 500 Internal Server Error のレスポンスを返す。
D. Datastore が HTTP 2xx のレスポンスを返すまで、指数バックオフを使用して Datastore API を再試行する。
